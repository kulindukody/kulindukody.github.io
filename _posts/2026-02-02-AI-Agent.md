---
title: "Creating an AI Pentest Agent - Part 2"
date: 2026-02-02 00:00:00 +0000
categories: [AI/ML]
tags: [AI/ML]
---
# Introduction
So in the previous blog i walked you through the theoretical aspect of what AI and ML are so in this blog i will cover how to make your first model and how things work on the practical level.

So as always before you start something you need prerequisites i will walk you through all the steps you can follow along. 

# Making the Model
## Check for Python
Initially check if python is installed in your computer
```
PS C:\Users\TUF\Documents\Projects\AI Agent> python --version
Python 3.13.5
```

## Create Virtual Environment
Then open visual studio in a folder you want to do this on, and then create a virtual environment.
```
PS C:\Users\TUF\Documents\Projects\AI Agent> python -m venv venv
PS C:\Users\TUF\Documents\Projects\AI Agent> .\venv\Scripts\activate
(venv) PS C:\Users\TUF\Documents\Projects\AI Agent>
```

## Install the Core libraries
Once this is out of the way install the following libraries to start working on the model.
```
pip install numpy pandas scikit-learn matplotlib
```

So this is what the libraries do and this is why they are needed to be installed.

| Library      | Purpose          |
| ------------ | ---------------- |
| numpy        | Math & arrays    |
| pandas       | Dataset handling |
| scikit-learn | ML models        |
| matplotlib   | Graphs           |
## Create your first Dataset (Manual)
Since this is a small demo ill use a custom made list, but feel free to experiment with datasets you find in platforms like kaggle.
```
response_length,error_detected,status_changed,label
1200,1,0,SQLi
1195,1,0,SQLi
980,0,0,None
1020,0,0,None
```

## Train your model
```
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Load data
df = pd.read_csv("data.csv")

# Drop rows without labels
df = df.dropna(subset=["label"])
print(df)
print("\nNaN count per column:")
print(df.isna().sum())
 
# Split features and labels
X = df.drop("label", axis=1)
y = df["label"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
 
# Model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Predict
predictions = model.predict(X_test) 
print("Accuracy:", accuracy_score(y_test, predictions))
```

```
(venv) PS C:\Users\TUF\Documents\Projects\AI Agent> python .\train.py
   response_length  error_detected  status_changed label
0             1200               1               0  SQLi
1             1195               1               0  SQLi

NaN count per column:
response_length    0
error_detected     0
status_changed     0
label              0
dtype: int64
Accuracy: 1.0
```

## What do i mean by training
Training means I'm adjusting internal parameters so:
```
Prediction ≈ Correct label
```

The model sees many examples and it finds patterns and minimizes error, models do not understand meaning the just correlate numbers. 

# Common misconceptions
- More data Fixes Everything
	- No it does not, you need a solid set of features to identify different patterns and classify them so more data wont fix the issue proper features will.
- High Accuracy is good
	- Not per say 
    
So with this i think i have covered the basic part of how training a model works, in the next set of blogs ill talk about the architecture of an AI Agent and what is an ai agent.

